{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(path,size):\n",
    "    faces = np.zeros([size,224,224,3])\n",
    "    for i in range(size):\n",
    "        img = image.load_img('{}/{}.jpg'.format(path,i))\n",
    "        faces[i,:,:] = img\n",
    "#         if(i%100==0):\n",
    "#             print(\"done with {} images\".format(i))\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n"
     ]
    }
   ],
   "source": [
    "proportional_train = load_faces('samples/adience_sample_1_train',500)\n",
    "proportional_val = load_faces('samples/adience_sample_1_val',500)\n",
    "equal_sub_train = load_faces('samples/adience_sample_2_train',500)\n",
    "equal_sub_val = load_faces('samples/adience_sample_2_val',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_faces(faces):\n",
    "    l = faces.shape[0]\n",
    "    processed_faces = np.zeros([l,224,224,3])\n",
    "    for i in range(l):\n",
    "        x = np.expand_dims(faces[i], axis = 0)\n",
    "        x = preprocess_input(x)\n",
    "        processed_faces[i,:,:] = x\n",
    "        if(i%100==0):\n",
    "            print(\"done with {} images\".format(i))\n",
    "    return processed_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n",
      "done with 0 images\n",
      "done with 100 images\n",
      "done with 200 images\n",
      "done with 300 images\n",
      "done with 400 images\n"
     ]
    }
   ],
   "source": [
    "prop_train = process_faces(proportional_train)\n",
    "prop_val = process_faces(proportional_val)\n",
    "eq_sub_train = process_faces(equal_sub_train)\n",
    "eq_sub_val = process_faces(equal_sub_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in metadata\n",
    "# sample 1: proportional classes (as compared to adience dataset)\n",
    "sample1_train = pd.read_csv('samples/sample_1_train.csv')\n",
    "sample1_val = pd.read_csv('samples/sample_1_val.csv')\n",
    "\n",
    "# sample 2: equal classes\n",
    "sample2_train = pd.read_csv('samples/sample_2_train.csv')\n",
    "sample2_val = pd.read_csv('samples/sample_2_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prop = sample1_train['gender_y']\n",
    "y_val_prop = sample1_val['gender_y']\n",
    "\n",
    "y_train_eq = sample2_train['gender_y']\n",
    "y_val_eq = sample2_val['gender_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prop = to_categorical(y_train_prop.map({'f':0,'m':1}),num_classes=2)\n",
    "y_val_prop = to_categorical(y_val_prop.map({'f':0,'m':1}),num_classes=2)\n",
    "\n",
    "y_train_eq = to_categorical(y_train_eq.map({'f':0,'m':1}),num_classes=2)\n",
    "y_val_eq = to_categorical(y_val_eq.map({'f':0,'m':1}),num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adience-style network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from scratch (mfs)\n",
    "# using the caffe model params as a guide\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "mfs = Sequential()\n",
    "\n",
    "# conv1\n",
    "mfs.add(Conv2D(filters = 96, kernel_size = 7, strides = 4,\n",
    "              activation = 'relu',input_shape = (224,224,3)))\n",
    "mfs.add(MaxPooling2D(pool_size = 3, strides = 2))\n",
    "\n",
    "# conv2\n",
    "mfs.add(Conv2D(filters = 256, kernel_size = 5, padding = 'same',\n",
    "              activation = 'relu'))\n",
    "mfs.add(MaxPooling2D(pool_size = 3, strides = 2))\n",
    "\n",
    "# conv3\n",
    "mfs.add(Conv2D(filters = 384, kernel_size = 3,\n",
    "              activation = 'relu'))\n",
    "mfs.add(MaxPooling2D(pool_size = 3, strides = 2))\n",
    "\n",
    "mfs.add(Dense(512, activation='relu'))\n",
    "mfs.add(Dropout(rate=0.5))\n",
    "mfs.add(Dense(512, activation='relu'))\n",
    "mfs.add(Dropout(rate=0.5))\n",
    "mfs.add(Flatten())\n",
    "mfs.add(Dense(8))\n",
    "mfs.add(Dense(2,activation='sigmoid'))\n",
    "\n",
    "# sgd = SGD(lr=.1, decay=0, momentum=0.9, nesterov=True)\n",
    "mfs.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 55, 55, 96)        14208     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 384)       885120    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5, 5, 512)         197120    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5, 5, 512)         262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 102408    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,076,186\n",
      "Trainable params: 2,076,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mfs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.8691 - acc: 0.5190 - val_loss: 0.7079 - val_acc: 0.5000\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.7181 - acc: 0.4970 - val_loss: 0.6916 - val_acc: 0.5280\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6930 - acc: 0.5210 - val_loss: 0.7083 - val_acc: 0.4570\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6996 - acc: 0.5120 - val_loss: 0.6893 - val_acc: 0.5490\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6993 - acc: 0.5360 - val_loss: 0.6889 - val_acc: 0.5220\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6838 - acc: 0.5690 - val_loss: 0.6845 - val_acc: 0.5810\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6772 - acc: 0.5780 - val_loss: 0.6787 - val_acc: 0.5870\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6803 - acc: 0.5780 - val_loss: 0.6685 - val_acc: 0.6140\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6662 - acc: 0.5870 - val_loss: 0.6573 - val_acc: 0.6350\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6606 - acc: 0.6070 - val_loss: 0.6479 - val_acc: 0.6400\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6468 - acc: 0.6310 - val_loss: 0.6349 - val_acc: 0.6630\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6364 - acc: 0.6340 - val_loss: 0.6353 - val_acc: 0.6820\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6284 - acc: 0.6550 - val_loss: 0.6306 - val_acc: 0.6670\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6072 - acc: 0.6840 - val_loss: 0.6371 - val_acc: 0.6430\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6060 - acc: 0.6860 - val_loss: 0.6290 - val_acc: 0.6560\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5924 - acc: 0.6900 - val_loss: 0.6215 - val_acc: 0.6740\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6037 - acc: 0.6570 - val_loss: 0.6442 - val_acc: 0.6660\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6045 - acc: 0.6760 - val_loss: 0.6287 - val_acc: 0.6580\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5509 - acc: 0.7130 - val_loss: 0.6769 - val_acc: 0.6350\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5527 - acc: 0.7220 - val_loss: 0.6289 - val_acc: 0.6510\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5239 - acc: 0.7470 - val_loss: 0.6451 - val_acc: 0.6580\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5151 - acc: 0.7250 - val_loss: 0.6677 - val_acc: 0.6560\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4652 - acc: 0.7770 - val_loss: 0.6436 - val_acc: 0.6590\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4518 - acc: 0.7770 - val_loss: 0.7235 - val_acc: 0.6570\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4291 - acc: 0.7980 - val_loss: 0.6599 - val_acc: 0.6560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19b44c2e48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfs.fit(prop_train,y_train_prop,batch_size=128,epochs=25,verbose=1,\n",
    "        validation_data=(prop_val, y_val_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs.save_weights('mfs_weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs.save('mfs_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6923 - acc: 0.6380 - val_loss: 0.6412 - val_acc: 0.6510\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.6285 - acc: 0.6630 - val_loss: 0.6065 - val_acc: 0.6810\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5732 - acc: 0.6940 - val_loss: 0.5876 - val_acc: 0.6910\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.5389 - acc: 0.7300 - val_loss: 0.5820 - val_acc: 0.6920\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4927 - acc: 0.7790 - val_loss: 0.5777 - val_acc: 0.7160\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4729 - acc: 0.7900 - val_loss: 0.5698 - val_acc: 0.7290\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.4017 - acc: 0.8130 - val_loss: 0.5431 - val_acc: 0.7600\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.3410 - acc: 0.8580 - val_loss: 0.5601 - val_acc: 0.7300\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2940 - acc: 0.8860 - val_loss: 0.6641 - val_acc: 0.7000\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2467 - acc: 0.8910 - val_loss: 0.6653 - val_acc: 0.7410\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.1967 - acc: 0.9060 - val_loss: 0.7426 - val_acc: 0.7430\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2357 - acc: 0.9150 - val_loss: 0.8167 - val_acc: 0.6920\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2107 - acc: 0.9110 - val_loss: 0.9454 - val_acc: 0.7030\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.1967 - acc: 0.9200 - val_loss: 0.9008 - val_acc: 0.6900\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.1143 - acc: 0.9460 - val_loss: 0.8080 - val_acc: 0.7270\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.1033 - acc: 0.9650 - val_loss: 0.9939 - val_acc: 0.7230\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0636 - acc: 0.9760 - val_loss: 1.0688 - val_acc: 0.7140\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.0676 - acc: 0.9780 - val_loss: 1.2022 - val_acc: 0.7300\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0298 - acc: 0.9940 - val_loss: 1.1791 - val_acc: 0.7270\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0365 - acc: 0.9880 - val_loss: 1.4220 - val_acc: 0.7420\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0227 - acc: 0.9920 - val_loss: 1.3315 - val_acc: 0.7240\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0247 - acc: 0.9930 - val_loss: 1.3771 - val_acc: 0.7340\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0162 - acc: 0.9970 - val_loss: 1.7472 - val_acc: 0.7240\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 1.6763 - val_acc: 0.7260\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.0058 - acc: 0.9990 - val_loss: 1.6692 - val_acc: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19ad325e48>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfs.fit(equal_sub_train,y_train_eq,batch_size=128,epochs=25,verbose=1,\n",
    "        validation_data=(equal_sub_val, y_val_eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs.save_weights('mfs_weights_2.h5')\n",
    "mfs.save('mfs_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
      "58916864/58909280 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)\n",
    "custom_vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.fit(processed_faces[:100],y_cat[:100],batch_size=64,epochs=100,verbose=1,\n",
    "        validation_data=(processed_faces[100:125], y_cat[100:125]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
